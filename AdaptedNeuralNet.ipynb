{"cells":[{"cell_type":"markdown","metadata":{"id":"0Wzfawi4wdhI"},"source":["Code Manual: \\\\\n","-In order for the whole thing to run, the root folder has to contain 'images', 'labels', and 'videos' folders \\\\\n","-Run each section, but interact only with console \\\\\n","- Put the root to your Data into \"root\" variable \\\\\n","- Put your Weights & Biases key into key"]},{"cell_type":"markdown","metadata":{"id":"KgairetbVKAX"},"source":["#Install packages"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"YhrZ4laBVFFE","executionInfo":{"status":"ok","timestamp":1701040575426,"user_tz":300,"elapsed":17114,"user":{"displayName":"greendeilab","userId":"08873200893633514555"}}},"outputs":[],"source":["#mounting a drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","#installing yolo5\n","! git clone https://github.com/ultralytics/yolov5 # clone repo\n","! pip install -r yolov5/requirements.txt  # install\n","! cp -r yolov5/utils .\n","! pip install wandb\n","\n","#installing packages\n","from torchvision import transforms as T\n","import xml.etree.ElementTree as et\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from PIL import ImageDraw, ImageFont\n","import os\n","import cv2\n","import numpy as np\n","import shutil as s\n","import random as r\n","import torch\n","import time\n","import sys\n","import wandb\n","from IPython.display import clear_output\n","\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"yNWqe-kqyUIY"},"source":["#MAIN PART"]},{"cell_type":"markdown","metadata":{"id":"5ecjpqUoy4pF"},"source":["#Transformation"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"nPhk-_qByma5","executionInfo":{"status":"ok","timestamp":1701040577610,"user_tz":300,"elapsed":2,"user":{"displayName":"greendeilab","userId":"08873200893633514555"}}},"outputs":[],"source":["#In order for a class to run there has to be a folder with two folders called\n","#images and labels.\n","\n","class Transform():\n","  def __init__(self, root):\n","    self.root = root\n","    self.img_dir = f'{self.root}/images'\n","    self.label_dir = f'{self.root}/labels'\n","    self.img_files = os.listdir(self.img_dir)\n","    self.label_files = os.listdir(self.label_dir)\n","\n","  def horizontalFlip(self, img):\n","    transforms = T.Compose([T.ToTensor(), T.RandomHorizontalFlip(1), T.ToPILImage()])\n","    new_img = transforms(img)\n","    return new_img\n","\n","  def verticalFlip(self, img):\n","    transforms = T.Compose([T.ToTensor(), T.RandomVerticalFlip(1), T.ToPILImage()])\n","    new_img = transforms(img)\n","    return new_img\n","\n","  def autoContrast(self, img):\n","    transforms = T.Compose([T.ToTensor(), T.RandomAutocontrast(1), T.ToPILImage()])\n","    new_img = transforms(img)\n","    return new_img\n","\n","  def brightnessChange(self, img):\n","    transforms = T.Compose([T.ToTensor(), T.ColorJitter(0.6), T.ToPILImage()])\n","    new_img = transforms(img)\n","    return new_img\n","\n","  def gaussianBlur(self, img):\n","    transforms = T.Compose([T.ToTensor(), T.GaussianBlur(kernel_size=(101), sigma=(10,50)), T.ToPILImage()])\n","    new_img = transforms(img)\n","    return new_img\n","\n","  # image needs to be read as cv2\n","  def grayscale(self, img):\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    gray = np.array(gray / gray.max() * 255, dtype=np.uint8)\n","    new_img = Image.fromarray(gray)\n","    return new_img\n","\n","  def clearFolders(self):\n","    for img in self.img_files:\n","      if '_VFlip' or '_HFlip' or '_contrast' or '_bright' or '_gray' or'_blur' in img:\n","        os.remove(f'{self.img_dir}/{img}')\n","    for label in self.label_files:\n","      if '_VFlip' or '_HFlip' or '_contrast' or '_bright' or '_gray' or'_blur' in label:\n","        os.remove(f'{self.label_dir}/{label}')\n","\n","  def saveAndUpdateTransformedImageAndTXT(self, img_name, function, new_img):\n","    if function == 'HFlip': aspects_ratio = 1\n","    elif function == 'VFlip': aspects_ratio = 2\n","    else: aspects_ratio = 0\n","\n","    # Getting the label\n","    try:\n","      label = open(f'{self.label_dir}/{img_name}.txt', 'r')\n","    except:\n","      return None\n","\n","    # Updating the image file\n","    new_img.save(f'{self.img_dir}/{img_name}_{function}.jpg')\n","\n","    # Getting all the corresponding boxes\n","    new_aspects = []\n","    for line in label:\n","      elements = line.split()\n","      aspects = [int(elements[0])] + [float(value) for value in elements[1:]]\n","      if aspects_ratio != 0:\n","        aspects[aspects_ratio] = 1 - aspects[aspects_ratio]\n","      new_aspects.append(aspects)\n","\n","    # Updating txt file\n","\n","    new_file = open(f'{self.label_dir}/{img_name}_{function}.txt', 'w')\n","    for elements in new_aspects:\n","      new_file.write(f'{elements[0]} {elements[1]} {elements[2]} {elements[3]} {elements[4]}\\n')\n","    new_file.close()\n","    return None\n","\n","  def performTransformations(self, doHFlip = False, doVFlip = False, doContrast = False, doBright = False, doGray = False, doBlur = False):\n","    for i in range(len(self.img_files)):\n","      # Open the image\n","      img = Image.open(f'{self.img_dir}/{self.img_files[i]}')\n","      img_for_grayscale = cv2.imread(f'{self.img_dir}/{self.img_files[i]}')\n","      img_name = self.img_files[i][:-4]\n","      if doHFlip == True:\n","        new_img = self.horizontalFlip(img)\n","        self.saveAndUpdateTransformedImageAndTXT(img_name, 'HFlip', new_img)\n","      if doVFlip == True:\n","        new_img = self.verticalFlip(img)\n","        self.saveAndUpdateTransformedImageAndTXT(img_name, 'VFlip', new_img)\n","      if doContrast == True:\n","        new_img = self.autoContrast(img)\n","        self.saveAndUpdateTransformedImageAndTXT(img_name, 'contrast', new_img)\n","      if doBright == True:\n","        new_img = self.brightnessChange(img)\n","        self.saveAndUpdateTransformedImageAndTXT(img_name, 'bright', new_img)\n","      if doGray == True:\n","        new_img = self.grayscale(img_for_grayscale)\n","        self.saveAndUpdateTransformedImageAndTXT(img_name, 'gray', new_img)\n","      if doBlur == True:\n","        new_img = self.gaussianBlur(img)\n","        self.saveAndUpdateTransformedImageAndTXT(img_name, 'blur', new_img)"]},{"cell_type":"markdown","metadata":{"id":"HkqYTKTCy659"},"source":["#Training"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"wKufZnQOyuPD","executionInfo":{"status":"ok","timestamp":1701039807452,"user_tz":300,"elapsed":7,"user":{"displayName":"greendeilab","userId":"08873200893633514555"}}},"outputs":[],"source":["#In order for a class to run there has to be a folder with two folders called\n","#images and labels.\n","\n","class Train():\n","  def __init__(self, root, number_of_classes, names):\n","    self.root = root\n","    self.number_of_classes = number_of_classes\n","    self.names = names\n","    self.img_dir = f'{root}/images'\n","    self.label_dir = f'{root}/labels'\n","    try:\n","      self.imgs = os.listdir(self.img_dir)\n","    except FileNotFoundError:\n","      self.imgs = []\n","\n","  def createFolderDrive(self, path):\n","    try:\n","      os.mkdir(path)\n","    except FileExistsError:\n","      s.rmtree(path, ignore_errors=True)\n","      os.mkdir(path)\n","\n","  def yamlFileMountYolo(self):\n","    yamlFileName = os.path.join(self.root, 'training_data.yaml')\n","    yamlFile = open(yamlFileName, \"w\")\n","    yamlFile.write(f'path: ./\\ntrain: train/images/\\nval: val/images/\\ntest:\\nnc: {self.number_of_classes}\\nnames: {self.names}')\n","    yamlFile.close()\n","    path = f'{self.root}/training_data.yaml'\n","    ! cp $path '.'\n","\n","  def getBrokenPaths(self, root_labels, labels):\n","    root_jpg = root_labels[:-6] + 'images'\n","    brokenLabelPaths = []\n","    brokenJPG = []\n","    for file_name in labels:\n","      txt_file = open(f'{root_labels}/{file_name}', 'r')\n","      for count, line in enumerate(txt_file):\n","        pass\n","      num_lines = count+1\n","      if num_lines > self.number_of_classes:\n","        brokenLabelPaths.append(f'{root_labels}/{file_name}')\n","        jpg_name = file_name[:-4] + '.jpg'\n","        print(f'{jpg_name} file has more classes than were printed by the user')\n","        brokenJPG.append(f'{root_jpg}/{jpg_name}')\n","    return brokenLabelPaths, brokenJPG\n","\n","  def DeleteBrokenLabels(self):\n","    error_threshold = 0.5\n","    root_labels = f'{self.root}/labels'\n","    val_labels = f'{self.root}/val/labels'\n","    train_labels = f'{self.root}/train/labels'\n","    files = []\n","    files_val = []\n","    files_train = []\n","    brokenLabelPaths = []\n","    brokenJPGPaths = []\n","    root_labels_exist = True\n","    try:\n","      files = os.listdir(root_labels)\n","    except FileNotFoundError:\n","      root_labels_exist = False\n","      files_val = os.listdir(val_labels)\n","      files_train = os.listdir(train_labels)\n","\n","    if root_labels_exist:\n","      paths = self.getBrokenPaths(root_labels, files)\n","      brokenLabelPaths.append(paths[0])\n","      brokenJPGPaths.append(paths[1])\n","    else:\n","      paths_val = self.getBrokenPaths(val_labels, files_val)\n","      paths_train = self.getBrokenPaths(train_labels, files_train)\n","\n","      brokenLabelPaths = paths_val[0] + paths_train[0]\n","      brokenJPGPaths = paths_val[1] + paths_train[1]\n","    if len(brokenLabelPaths) > (len(files) + len(files_val) + len(files_train)) * error_threshold:\n","      return 'You either have a broken data set or your number of classes is incorrect'\n","    else:\n","      for brokenLabel in brokenLabelPaths:\n","        os.remove(brokenLabel)\n","      for brokenJPG in brokenJPGPaths:\n","        os.remove(brokenJPG)\n","      return 'Deleted unnecessary files'\n","\n","  def splitValAndTrain(self, split_ratio):\n","    val_size = int(len(self.imgs) * split_ratio)\n","    train_size = len(self.imgs) - val_size\n","\n","    #Making corresponding val and train folders in Drive\n","    self.createFolderDrive(os.path.join(self.root, 'val'))\n","    self.createFolderDrive(os.path.join(self.root, 'train'))\n","\n","    #Populating new directories with folders\n","    self.createFolderDrive(os.path.join(f'{self.root}/train', 'images'))\n","    self.createFolderDrive(os.path.join(f'{self.root}/train', 'labels'))\n","    self.createFolderDrive(os.path.join(f'{self.root}/val', 'images'))\n","    self.createFolderDrive(os.path.join(f'{self.root}/val', 'labels'))\n","\n","    destination_train_imgs = f'{self.root}/train/images'\n","    destination_train_labels = f'{self.root}/train/labels'\n","    destination_val_imgs = f'{self.root}/val/images'\n","    destination_val_labels = f'{self.root}/val/labels'\n","\n","    for i in range(val_size):\n","      choice = r.choice(self.imgs)\n","      choice_label = choice[:-3] + 'txt'\n","      try:\n","        s.move(f'{self.img_dir}/{choice}', f'{destination_val_imgs}/{choice}')\n","        s.move(f'{self.label_dir}/{choice_label}', f'{destination_val_labels}/{choice_label}')\n","        self.imgs.remove(choice)\n","      except:\n","        self.imgs.remove(choice)\n","\n","    for j in range(train_size):\n","      choice = r.choice(self.imgs)\n","      choice_label = choice[:-3] + 'txt'\n","      try:\n","        s.move(f'{self.img_dir}/{choice}', f'{destination_train_imgs}/{choice}')\n","        s.move(f'{self.label_dir}/{choice_label}', f'{destination_train_labels}/{choice_label}')\n","        self.imgs.remove(choice)\n","      except:\n","        self.imgs.remove(choice)\n","\n","    #remove used directories\n","    s.rmtree(self.img_dir, ignore_errors=True)\n","    s.rmtree(self.label_dir, ignore_errors=True)\n","\n","  def TrainModel(self, project_name = 'DF', batch = 32, epochs = 250):\n","    path_val = f'{self.root}/val'\n","    path_train = f'{self.root}/train'\n","    path_train_zip = f'{path_train}.zip'\n","    path_val_zip = f'{path_val}.zip'\n","\n","    #zipping and transferring to different machine\n","    s.make_archive(f'{path_val}', 'zip', f'{self.root}', 'val')\n","    s.make_archive(f'{path_train}', 'zip', f'{self.root}', 'train')\n","    ! cp $path_val_zip 'yolov5/'\n","    ! cp $path_train_zip 'yolov5/'\n","\n","    #unzipping packages on different machine\n","    s.unpack_archive(f'{path_train_zip}', 'yolov5/', 'zip')\n","    s.unpack_archive(f'{path_val_zip}', 'yolov5/', 'zip')\n","\n","    #training the data\n","    name = f'v5s_640_{batch}_{epochs}'\n","    path_yaml = f'{self.root}/training_data.yaml'\n","    ! python yolov5/train.py --save-period 2 --project $project_name --name $name --img 640 --batch $batch --epochs $epochs --data training_data.yaml --weights yolov5s.pt\n","\n","    #getting data back\n","    root_best = f'{project_name}/{name}/weights/best.pt'\n","    root_last = f'{project_name}/{name}/weights/last.pt'\n","    self.createFolderDrive(os.path.join(self.root, 'trained'))\n","    root_train = f'{self.root}/trained'\n","    ! cp $root_best $root_train\n","    ! cp $root_last $root_train"]},{"cell_type":"markdown","metadata":{"id":"H0m60FzlzJM4"},"source":["#Analysis"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ZUQdTOT5zHlD","executionInfo":{"status":"ok","timestamp":1701039807452,"user_tz":300,"elapsed":6,"user":{"displayName":"greendeilab","userId":"08873200893633514555"}}},"outputs":[],"source":["def find_best_path(root):\n","    for root, dirs, files in os.walk(root):\n","      for name in files:\n","        if name.find('best') != -1:\n","          return os.path.join(root, name)\n","\n","class Analysis():\n","  def __init__(self, root, score_lim, only_npys, FPS):\n","    self.root = root\n","    self.instances = {}\n","    self.results = []\n","    self.model = torch.hub.load('ultralytics/yolov5', 'custom', path=find_best_path(root), force_reload = True)\n","    self.num_of_videos = 0\n","    self.score_lim = score_lim\n","    self.scaling_factor = 0.5 # doesn't affect performance at all\n","    self.only_npys = only_npys\n","    self.FPS = FPS\n","    #time constants\n","    self.time_start = time.perf_counter()\n","    self.initial_time = time.perf_counter()\n","    self.progress = 0\n","    self.video_num = 1\n","    self.num_of_videos = len(self.locate_video_paths())\n","\n","  def producePredictions(self, frame):\n","    self.results = self.model(frame)\n","    return self.results.xyxy[0].detach().cpu().numpy()\n","\n","  def createNPYs(self, frame_num, predictions):\n","    self.instances[frame_num] = predictions\n","    return None\n","\n","  def frameFirstTransform(self, frame, scaling_factor):\n","    frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n","    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    return Image.fromarray(frame)\n","\n","  def frameSecondTransform(self, frame, scaling_factor):\n","    frame = cv2.cvtColor(np.asarray(frame), cv2.COLOR_RGB2BGR)\n","    frame = cv2.resize(frame, None, fx=(1/scaling_factor), fy=(1/scaling_factor), interpolation=cv2.INTER_AREA)\n","    return frame\n","\n","  def drawBoxes(self, img, predictions, score_threshold):\n","    img1 = ImageDraw.Draw(img)\n","    for boxes in predictions:\n","      if boxes.tolist() != []:\n","        color_code = int(boxes[5])\n","        score = boxes[4]\n","        box = boxes[:4]\n","\n","        # I picked random constants for RGB. You might pick different ones\n","        R, G, B, step = 220, 30, 30, 60\n","\n","        color = ((color_code*step + R)%255, (color_code*step + G)%255, (color_code*step + B)%255)\n","        if score > score_threshold:\n","          img1.rectangle(box, outline = \"black\", width=1)\n","          img1.rectangle(box, outline = color, width=2)\n","    return img\n","\n","\n","  def analyze_video(self, path):\n","    self.instances = {}\n","    self.progress = 0\n","    video = cv2.VideoCapture(path)\n","    if video.isOpened() == False:\n","      return None\n","    else:\n","      frame_width = int(video.get(3))\n","      frame_height = int(video.get(4))\n","      size = (frame_width, frame_height)\n","      length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n","    name = f'{path}'\n","    name = name[:-4]\n","    if self.only_npys == False:\n","      result = cv2.VideoWriter(f'{name}_yolo.avi', cv2.VideoWriter_fourcc(*'MJPG'),\n","                              self.FPS, size)\n","    frame_num = 0\n","    t0 = time.perf_counter()\n","    while video.isOpened():\n","      self.progress = round(frame_num / length * 100, 1)\n","      tx = time.perf_counter()\n","      if tx - t0 > 10:\n","        print(f'Program is done analyzing video {self.video_num}/{self.num_of_videos} by {self.progress}%')\n","        t0 = time.perf_counter()\n","      ret, frame = video.read()\n","      if ret:\n","        if self.scaling_factor != 1:\n","          frame = self.frameFirstTransform(frame, self.scaling_factor)\n","          predictions = self.producePredictions(frame)\n","          if self.only_npys == False:\n","            predicted_frame = self.drawBoxes(frame, predictions, self.score_lim)\n","            predicted_frame = self.frameSecondTransform(frame, self.scaling_factor)\n","            result.write(predicted_frame)\n","            self.createNPYs(frame_num, predictions)\n","          else:\n","            self.createNPYs(frame_num, predictions)\n","        else:\n","          predictions = self.producePredictions(frame)\n","          if self.only_npys == False:\n","            predicted_frame = self.drawBoxes(frame, predictions, self.score_lim)\n","            result.write(predicted_frame)\n","            self.createNPYs(frame_num, predictions)\n","          else:\n","            self.createNPYs(frame_num, predictions)\n","        frame_num += 1\n","      else:\n","        break\n","\n","    video.release()\n","    if self.only_npys == False:\n","      result.release()\n","    cv2.destroyAllWindows()\n","\n","    if self.instances != {}:\n","      # Save the predictions\n","      dictionary_path = f'{path}'[:-4]\n","      video_name = dictionary_path.split('/')[-1]\n","      path ='/'.join(dictionary_path.split('/')[:-1])\n","      if path.find('compass') != -1 or path.find('Compass') != -1 or path.find('COMPASS') != -1 or path.find('COMP') != -1 or path.find('comp') != -1:\n","        video_name += '_compass'\n","      if os.path.exists(path+'/predictions'):\n","        np.save(path+'/predictions/'+video_name+'.npy', self.instances)\n","      else:\n","        os.mkdir(path+'/predictions')\n","        np.save(path+'/predictions/'+video_name+'.npy', self.instances)\n","\n","  def locate_prediction_names(self):\n","    names = []\n","    prediction_type = '.npy'\n","    for root, dirs, files in os.walk(self.root):\n","      for name in files:\n","        file_type = name[-4:]\n","        if file_type == prediction_type:\n","          name = name.replace('_yolo', '')\n","          name = name.replace('_predictions', '')\n","          name = name.replace('_compass', '')\n","          names.append(name[:-4])\n","    return names\n","\n","  def locate_video_paths(self):\n","    predictions = self.locate_prediction_names()\n","    paths = []\n","    file_types = ['.avi', '.AVI', '.mov', '.MOV', '.mp4', '.MP4']\n","    for root, dirs, files in os.walk(self.root):\n","      for name in files:\n","        file_type = name[-4:]\n","        yolo_check = name[-8:-4]\n","        if file_type in file_types and yolo_check != 'yolo' and name[:-4] not in predictions:\n","          paths.append(os.path.join(root, name))\n","    return paths\n","\n","  def perform_analysis(self):\n","    paths = self.locate_video_paths()\n","    for path in paths:\n","      self.analyze_video(path)\n","      self.video_num += 1"]},{"cell_type":"markdown","metadata":{"id":"3R3DDmMKzNz7"},"source":["Neural Network"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"AIDbBcpWySxX","executionInfo":{"status":"ok","timestamp":1701040128622,"user_tz":300,"elapsed":337,"user":{"displayName":"greendeilab","userId":"08873200893633514555"}}},"outputs":[],"source":["class NeuralNetwork():\n","  def __init__(self, root, key):\n","    self.root = root\n","    self.transformations_bools = [False, False, False, False, False, False]\n","    self.key = key\n","    self.batches = 0\n","    self.epochs = 0\n","\n","  def createFolderDrive(self, path):\n","    try:\n","      os.mkdir(path)\n","    except FileExistsError:\n","      s.rmtree(path, ignore_errors=True)\n","      os.mkdir(path)\n","\n","  def moveObject(self, path_start, path_end):\n","    try:\n","      s.move(path_start, path_end)\n","    except FileExistsError:\n","      os.remove(path_end)\n","      s.move(path_start, path_end)\n","\n","  def RestoreTraining(self, run_path, batches, epochs):\n","    path_val = f'{self.root}/val'\n","    path_train = f'{self.root}/train'\n","    path_train_zip = f'{path_train}.zip'\n","    path_val_zip = f'{path_val}.zip'\n","\n","    name = f'v5s_640_{batches}_{epochs}'\n","    project_name = run_path.split('/')[1]\n","    path_yaml = f'{self.root}/training_data.yaml'\n","    ! cp $path_yaml '.'\n","\n","    ! cp $path_val_zip 'yolov5/'\n","    ! cp $path_train_zip 'yolov5/'\n","\n","    s.unpack_archive(f'{path_train_zip}', 'yolov5/', 'zip')\n","    s.unpack_archive(f'{path_val_zip}', 'yolov5/', 'zip')\n","\n","    ! wandb artifact get $run_path --root restored_model\n","    ! python yolov5/train.py --resume restored_model/last.pt --save-period 2\n","\n","    root_best = f'{project_name}/{name}/weights/best.pt'\n","    root_last = f'{project_name}/{name}/weights/last.pt'\n","    self.createFolderDrive(os.path.join(self.root, 'trained'))\n","    root_train = f'{self.root}/trained'\n","    ! cp $root_best $root_train\n","    ! cp $root_last $root_train\n","\n","  def clean_root(self):\n","    self.createFolderDrive(os.path.join(f'{self.root}', 'output_videos'))\n","    self.createFolderDrive(os.path.join(f'{self.root}', 'output_npys'))\n","    appended_files = []\n","\n","    for root, dirs, files in os.walk(self.root):\n","      for name in files:\n","        avi_yolo_check = name[-8:]\n","        npy_check = name[-4:]\n","        if avi_yolo_check == 'yolo.avi' and name not in appended_files:\n","          self.moveObject(os.path.join(root, name), f'{self.root}/output_videos')\n","          appended_files.append(name)\n","        elif npy_check == '.npy' and name not in appended_files:\n","          self.moveObject(os.path.join(root, name), f'{self.root}/output_npys')\n","          appended_files.append(name)\n","    # Add the deletion of everything part\n","    folders = ['train', 'val', 'videos']\n","    files = ['train.zip', 'training_data.yaml', 'val.zip']\n","    for folder in folders:\n","      s.rmtree(os.path.join(self.root, folder), ignore_errors=True)\n","    for filE in files:\n","      os.remove(os.path.join(self.root, filE))\n","\n","  def transformationsConsole(self):\n","      booleans = ['Vertical Flip', 'Horizontal Flip', 'Contrast Shift', 'Brightness Shift', 'Grayscale', 'Blur']\n","      counter = 0\n","      while counter != len(booleans)-1:\n","        boolean = booleans[counter]\n","        print(f'Do you want to perform {boolean}? (+)(-)')\n","        line = str(input())\n","        if line == '+':\n","          self.transformations_bools[counter] = True\n","          counter += 1\n","        elif line == '-':\n","          self.transformations_bools[counter] = False\n","          counter += 1\n","      my_transform = Transform(self.root)\n","      my_transform.performTransformations(doHFlip = self.transformations_bools[0], doVFlip = self.transformations_bools[1],\n","                  doContrast = self.transformations_bools[2], doBright = self.transformations_bools[3],\n","                  doGray = self.transformations_bools[4], doBlur = self.transformations_bools[5])\n","      print('Transforms are succesfully completed!')\n","\n","  def trainingConsole(self):\n","    print('Do you want to restore already existing model? (+)(-)')\n","    restoration_check = str(input())\n","    if restoration_check == '+':\n","      print('Copy and paste the path to your last checkpoint from W&B (Go to your project -> Artifacts -> model -> pick the last one -> copy \"Full Name\" which is a link):')\n","      run_path = str(input())\n","      print('How many batches did you use? Type this number:')\n","      batches = str(input())\n","      print('How many epochs did you use? Type this number:')\n","      epochs = str(input())\n","      self.RestoreTraining(run_path, batches, epochs)\n","    else:\n","      print('How many classes of objects do you want to identify?')\n","      nc = int(input())\n","      names = []\n","      for i in range(nc):\n","        print('Type the name of the class:')\n","        names.append(str(input()))\n","      my_train = Train(self.root, nc, names)\n","      #print(my_train.DeleteBrokenLabels())\n","      my_train.yamlFileMountYolo()\n","      print('Have you already splitted val and train? (+)(-)')\n","      split_bool = str(input())\n","      if split_bool == '-':\n","        print('In which ratio do you want to split your data into train and val (val:(train+val))? Input a number between 0 and 1')\n","        ratio = float(input())\n","        if ratio > 1 or ratio < 0:\n","          while ratio > 1 or ratio <0:\n","            print('Input a correct ratio from 0 to 1')\n","            ratio = float(input())\n","        else:\n","          my_train.splitValAndTrain(ratio)\n","      print('Your project name is DF, number of batches is 32, and number of epochs is 250. Do you want to change that? (+)(-)')\n","      if str(input()) == '+':\n","        print('Your desired project name:')\n","        project_names = str(input())\n","        print('Your desired number of batches:')\n","        self.batches = int(input())\n","        print('Your desired number of epochs:')\n","        self.epochs = int(input())\n","        my_train.TrainModel(project_name = project_names, batch = self.batches, epochs = self.epochs)\n","      else:\n","        my_train.TrainModel()\n","      print('Training is sucessfully completed!')\n","\n","  def analysisConsole(self):\n","    print('Do you want to produce NPY files only? (+)(-)')\n","    NPY_check = str(input())\n","    if NPY_check == '+':\n","      npy = True\n","      score = 0.8\n","      FPS = 120\n","    else:\n","      print('Your score threshold is set to 0.8. Do you want to change that? (+)(-)')\n","      score_check = str(input())\n","      if score_check == '+':\n","        print('What do you want to change it to?')\n","        score = float(input())\n","      else:\n","        score = 0.8\n","      print('What is the FPS of your video?')\n","      FPS = int(input())\n","      npy = False\n","    my_analysis = Analysis(self.root, score, npy, FPS)\n","    my_analysis.perform_analysis()\n","\n","  def mainConsole(self):\n","    #Transformations\n","    print('Do you want to perform transformations? (+)(-)')\n","    transform_check = str(input())\n","    if transform_check == '+':\n","      self.transformationsConsole()\n","\n","    # Training part\n","    wandb.login(key=self.key)\n","    print('Do you want to train or restore training of your model? (+)(-)')\n","    training_check = str(input())\n","    if training_check == '+':\n","      self.trainingConsole()\n","\n","    #Analysis part\n","    print('Do you want to perform analysis? (+)(-)')\n","    analysis_check = str(input())\n","    if analysis_check == '+':\n","      self.analysisConsole()\n","\n","    #Delete and restructure part\n","    print('Do you want to restructure your root folder? (+)(-)')\n","    restructure_check = str(input())\n","    if restructure_check == '+':\n","      self.clean_root()"]},{"cell_type":"markdown","metadata":{"id":"4NiG9YaXxiD9"},"source":["#Console"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":589},"id":"-8TijiGyzaKT","outputId":"c5190be2-801d-4ea8-880c-be4689e3a99e","executionInfo":{"status":"error","timestamp":1701040591722,"user_tz":300,"elapsed":8386,"user":{"displayName":"greendeilab","userId":"08873200893633514555"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Do you want to perform transformations? (+)(-)\n","+\n","Do you want to perform Vertical Flip? (+)(-)\n","+\n","Do you want to perform Horizontal Flip? (+)(-)\n","+\n","Do you want to perform Contrast Shift? (+)(-)\n","+\n","Do you want to perform Brightness Shift? (+)(-)\n","+\n","Do you want to perform Grayscale? (+)(-)\n","+\n","Error: local variable 'img' referenced before assignment\n"]},{"output_type":"error","ename":"UnboundLocalError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-25b93e865e1a>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mneural_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainConsole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-67ae1f05c5c9>\u001b[0m in \u001b[0;36mmainConsole\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mtransform_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtransform_check\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformationsConsole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# Training part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-67ae1f05c5c9>\u001b[0m in \u001b[0;36mtransformationsConsole\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m           \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mmy_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m       my_transform.performTransformations(doHFlip = self.transformations_bools[0], doVFlip = self.transformations_bools[1],\n\u001b[0m\u001b[1;32m     88\u001b[0m                   \u001b[0mdoContrast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformations_bools\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoBright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformations_bools\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                   doGray = self.transformations_bools[4], doBlur = self.transformations_bools[5])\n","\u001b[0;32m<ipython-input-13-aafc69e5c34a>\u001b[0m in \u001b[0;36mperformTransformations\u001b[0;34m(self, doHFlip, doVFlip, doContrast, doBright, doGray, doBlur)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdoHFlip\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mnew_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhorizontalFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAndUpdateTransformedImageAndTXT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HFlip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdoVFlip\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'img' referenced before assignment"]}],"source":["+\n","# Root provides a link to your directory where all your videos are as well as the model\n","# Also, if you want to perform Analysis from step 0, you have to have 3 folders: images, labels, videos\n","\n","#Key you will find after creating an account at Weights and Biases.\n","\n","root = '/content/drive/MyDrive/tongyuan_analysis/training_test'\n","key = '979abf5c61616bf151cbf82c3c8eca4d535324e9'\n","\n","\n","neural_network = NeuralNetwork(root, key)\n","\n","neural_network.mainConsole()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"V100","toc_visible":true,"authorship_tag":"ABX9TyNhg0Wi7xZzsWKuc9snQYYj"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}